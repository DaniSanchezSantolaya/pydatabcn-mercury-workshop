{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de2629c2",
   "metadata": {},
   "source": [
    "The workshop contains three different notebooks. Each one focuses on a different stage:\n",
    "    \n",
    "1. Dataset Generation. The first notebook (this one) focuses on generating a dataset for training the model. We will create a Robust Test Suite to check that the dataset generated meets certain conditions\n",
    "2. Model Training. The second notebook focuses on training the model. We will create a Robust Test Suite to check that the trained model meets certain conditions.\n",
    "3. Model Inference. In the last notebook, we use mercury.monitoring to monitor data drift and estimate the predicted performance of the model without having the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46b58863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(seed=2021)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ae305",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We will use the default credit card Dataset from the UCI machine learning repository. The dataset was used in [[1]](#[1]). Note that we will use a slightly modified version which contains a time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22503c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/uci_credit_drifted_historic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bfa1640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "      <th>REMAINDER_SENT</th>\n",
       "      <th>time</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>40000.0</td>\n",
       "      <td>38000.0</td>\n",
       "      <td>20239.0</td>\n",
       "      <td>13750.0</td>\n",
       "      <td>13770.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>380.0</td>\n",
       "      <td>601.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>1687.0</td>\n",
       "      <td>1542.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>260000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>21818.0</td>\n",
       "      <td>9966.0</td>\n",
       "      <td>8583.0</td>\n",
       "      <td>22301.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>630000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>6500.0</td>\n",
       "      <td>2870.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "1   500000.0    1          1         2   29      0      0      0      0   \n",
       "2   100000.0    2          2         2   23      0     -1     -1      0   \n",
       "3   260000.0    2          1         2   51     -1     -1     -1     -1   \n",
       "4   630000.0    2          2         2   41     -1      0     -1     -1   \n",
       "\n",
       "   PAY_5  ...  PAY_AMT1  PAY_AMT2  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0      0  ...    2000.0   36681.0   10000.0    9000.0     689.0     679.0   \n",
       "1      0  ...   55000.0   40000.0   38000.0   20239.0   13750.0   13770.0   \n",
       "2      0  ...     380.0     601.0       0.0     581.0    1687.0    1542.0   \n",
       "3     -1  ...   21818.0    9966.0    8583.0   22301.0       0.0    3640.0   \n",
       "4     -1  ...    1000.0    6500.0    6500.0    6500.0    2870.0       0.0   \n",
       "\n",
       "   default.payment.next.month  REMAINDER_SENT  time  id  \n",
       "0                           0               0     1   4  \n",
       "1                           0               0     1   6  \n",
       "2                           0               0     1   7  \n",
       "3                           0               0     1  11  \n",
       "4                           0               0     1  12  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbec40",
   "metadata": {},
   "source": [
    "## Prepare Dataset For Training\n",
    "\n",
    "Let's preparing the dataset for training the model. Our label will be the \"default.payment.next.month\" variable. We select the features that we want to use in our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b345614",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'default.payment.next.month'\n",
    "features = [c for c in df.columns if c not in [label, 'time', 'PAYMENT_DELAY', 'id']]\n",
    "#features = [c for c in df.columns if c not in [label, 'time', 'PAYMENT_DELAY', 'id', 'REMAINDER_SENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69aeca82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LIMIT_BAL',\n",
       " 'SEX',\n",
       " 'EDUCATION',\n",
       " 'MARRIAGE',\n",
       " 'AGE',\n",
       " 'PAY_0',\n",
       " 'PAY_2',\n",
       " 'PAY_3',\n",
       " 'PAY_4',\n",
       " 'PAY_5',\n",
       " 'PAY_6',\n",
       " 'BILL_AMT1',\n",
       " 'BILL_AMT2',\n",
       " 'BILL_AMT3',\n",
       " 'BILL_AMT4',\n",
       " 'BILL_AMT5',\n",
       " 'BILL_AMT6',\n",
       " 'PAY_AMT1',\n",
       " 'PAY_AMT2',\n",
       " 'PAY_AMT3',\n",
       " 'PAY_AMT4',\n",
       " 'PAY_AMT5',\n",
       " 'PAY_AMT6',\n",
       " 'REMAINDER_SENT']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce54b098",
   "metadata": {},
   "source": [
    "Now, let's define the function that will generate a train and test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c99c776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def prepare_dataset(df, features, label, test_size=0.3, random_state=42):\n",
    "    \n",
    "    # Only Keep Features and label\n",
    "    df = df[features + [label]]\n",
    "    \n",
    "    # Drop Duplicates\n",
    "    #df = df.drop_duplicates()\n",
    "    \n",
    "    # Split Train/Test\n",
    "    df_train, df_test = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return df, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f991c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7840, 25)\n",
      "(3360, 25)\n"
     ]
    }
   ],
   "source": [
    "df, df_train, df_test = prepare_dataset(df, features, label, test_size=0.3, random_state=SEED)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ae8b5",
   "metadata": {},
   "source": [
    "## Create Data Schema\n",
    "\n",
    "We now use [mercury.dataschema](https://bbva.github.io/mercury-dataschema/) to create a `DataSchema` which contains the feature types of the dataset. This will be used later when creating the Robust Tests. \n",
    "\n",
    "The `DataSchema` auto-infers the feature types, but we can also specify some feature types in case that the auto-inference doesn't work exactly as we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62379deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercury.dataschema import DataSchema\n",
    "from mercury.dataschema.feature import FeatType\n",
    "\n",
    "custom_feature_mapping = {\n",
    "    \"PAY_0\": FeatType.DISCRETE,\n",
    "    \"PAY_2\": FeatType.DISCRETE,\n",
    "    \"PAY_3\": FeatType.DISCRETE,\n",
    "    \"PAY_4\": FeatType.DISCRETE,\n",
    "    \"PAY_5\": FeatType.DISCRETE,\n",
    "    \"PAY_6\": FeatType.DISCRETE,\n",
    "}\n",
    "\n",
    "schema = DataSchema().generate(df_train, force_types=custom_feature_mapping).calculate_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f48e934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LIMIT_BAL': Discrete Feature (NAME=LIMIT_BAL, dtype=DataType.FLOAT),\n",
       " 'SEX': Binary Feature (NAME=SEX, dtype=DataType.INTEGER),\n",
       " 'EDUCATION': Categorical Feature (NAME=EDUCATION, dtype=DataType.INTEGER),\n",
       " 'MARRIAGE': Categorical Feature (NAME=MARRIAGE, dtype=DataType.INTEGER),\n",
       " 'AGE': Discrete Feature (NAME=AGE, dtype=DataType.INTEGER),\n",
       " 'PAY_0': Discrete Feature (NAME=PAY_0, dtype=DataType.INTEGER),\n",
       " 'PAY_2': Discrete Feature (NAME=PAY_2, dtype=DataType.INTEGER),\n",
       " 'PAY_3': Discrete Feature (NAME=PAY_3, dtype=DataType.INTEGER),\n",
       " 'PAY_4': Discrete Feature (NAME=PAY_4, dtype=DataType.INTEGER),\n",
       " 'PAY_5': Discrete Feature (NAME=PAY_5, dtype=DataType.INTEGER),\n",
       " 'PAY_6': Discrete Feature (NAME=PAY_6, dtype=DataType.INTEGER),\n",
       " 'BILL_AMT1': Discrete Feature (NAME=BILL_AMT1, dtype=DataType.FLOAT),\n",
       " 'BILL_AMT2': Discrete Feature (NAME=BILL_AMT2, dtype=DataType.FLOAT),\n",
       " 'BILL_AMT3': Discrete Feature (NAME=BILL_AMT3, dtype=DataType.FLOAT),\n",
       " 'BILL_AMT4': Discrete Feature (NAME=BILL_AMT4, dtype=DataType.FLOAT),\n",
       " 'BILL_AMT5': Discrete Feature (NAME=BILL_AMT5, dtype=DataType.FLOAT),\n",
       " 'BILL_AMT6': Discrete Feature (NAME=BILL_AMT6, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT1': Discrete Feature (NAME=PAY_AMT1, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT2': Discrete Feature (NAME=PAY_AMT2, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT3': Discrete Feature (NAME=PAY_AMT3, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT4': Discrete Feature (NAME=PAY_AMT4, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT5': Discrete Feature (NAME=PAY_AMT5, dtype=DataType.FLOAT),\n",
       " 'PAY_AMT6': Discrete Feature (NAME=PAY_AMT6, dtype=DataType.FLOAT),\n",
       " 'REMAINDER_SENT': Binary Feature (NAME=REMAINDER_SENT, dtype=DataType.INTEGER),\n",
       " 'default.payment.next.month': Binary Feature (NAME=default.payment.next.month, dtype=DataType.INTEGER)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema.feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f8645a",
   "metadata": {},
   "source": [
    "## Data Robust Tests\n",
    "\n",
    "We now [mercury.robust](https://bbva.github.io/mercury-robust/) to create tests to check that the generated dataset meets certain conditions.\n",
    "\n",
    "More concretely, we will create the next tests:\n",
    "1. [LinearCombinationsTest](https://bbva.github.io/mercury-robust/reference/data_tests/#mercury.robust.data_tests.LinearCombinationsTest): Ensures that the dataset doesn't have any linear combination between its numerical columns and no categorical variable is redundant\n",
    "2. [LabelLeakingTest](https://bbva.github.io/mercury-robust/reference/data_tests/#mercury.robust.data_tests.LabelLeakingTest): Ensures the target variable is not being leaked into the predictors.\n",
    "3. [NoisyLabelTest](https://bbva.github.io/mercury-robust/reference/data_tests/#mercury.robust.data_tests.NoisyLabelsTest): Looks if the labels of a dataset contain a high level of noise.\n",
    "4. [SampleLeakingTest](https://bbva.github.io/mercury-robust/reference/data_tests/#mercury.robust.data_tests.SampleLeakingTest): Looks if there are samples in the test dataset that are identical to samples in the base/train dataset.\n",
    "5. [NoDuplicatesTest](https://bbva.github.io/mercury-robust/reference/data_tests/#mercury.robust.data_tests.NoDuplicatesTest): Checks no duplicated samples are present in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "408b3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercury.robust.data_tests import (\n",
    "    LinearCombinationsTest,\n",
    "    LabelLeakingTest,\n",
    "    NoisyLabelsTest,\n",
    "    SampleLeakingTest,\n",
    "    NoDuplicatesTest\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0137546",
   "metadata": {},
   "source": [
    "We have two options to execute the tests: We can just execute one test individually, or alternatively, run a group of test in a `TestSuite`.\n",
    "\n",
    "Let's start running an individual test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63690468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearCombinationsTest\n",
    "linear_combinations = LinearCombinationsTest(df[features], dataset_schema=schema)\n",
    "linear_combinations.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f130fd",
   "metadata": {},
   "source": [
    "When no exception is raised, the test has run successfully. Let's try another test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f87cf3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedTestError",
     "evalue": "Test failed because high importance features were detected: ['REMAINDER_SENT']. Check for possible target leaking.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedTestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# LabelLeakingTest\u001b[39;00m\n\u001b[1;32m      2\u001b[0m label_leaking \u001b[38;5;241m=\u001b[39m LabelLeakingTest(\n\u001b[1;32m      3\u001b[0m     df[features \u001b[38;5;241m+\u001b[39m [label]], \n\u001b[1;32m      4\u001b[0m     label_name \u001b[38;5;241m=\u001b[39m label,\n\u001b[1;32m      5\u001b[0m     task \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     dataset_schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mlabel_leaking\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/mercury/robust/data_tests.py:558\u001b[0m, in \u001b[0;36mLabelLeakingTest.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    556\u001b[0m idxs \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfeature_importances[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures\u001b[39m\u001b[38;5;124m'\u001b[39m][high_importance_feats]\n\u001b[1;32m    557\u001b[0m names \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mcolumns[idxs]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m--> 558\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m FailedTestError((\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest failed because high importance features were detected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnames\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCheck for possible target leaking.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m ))\n",
      "\u001b[0;31mFailedTestError\u001b[0m: Test failed because high importance features were detected: ['REMAINDER_SENT']. Check for possible target leaking."
     ]
    }
   ],
   "source": [
    "# LabelLeakingTest\n",
    "label_leaking = LabelLeakingTest(\n",
    "    df[features + [label]], \n",
    "    label_name = label,\n",
    "    task = \"classification\",\n",
    "    dataset_schema=schema,\n",
    ")\n",
    "label_leaking.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c93939f",
   "metadata": {},
   "source": [
    "Now the test has failed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5d0881",
   "metadata": {},
   "source": [
    "## Test Suite\n",
    "\n",
    "Now we will group several test in a `TestSuite` and execute them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435142d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mercury.robust import TestSuite\n",
    "\n",
    "def create_suite(df, df_train, df_test, schema, features, label):\n",
    "\n",
    "    # LinearCombinationsTest\n",
    "    linear_combinations = LinearCombinationsTest(df[features], dataset_schema=schema)\n",
    "    \n",
    "    # LabelLeakingTest\n",
    "    label_leaking = LabelLeakingTest(\n",
    "        df[features + [label]], \n",
    "        label_name = label,\n",
    "        task = \"classification\",\n",
    "        dataset_schema=schema,\n",
    "    )\n",
    "    \n",
    "    # Noisy Labels\n",
    "    noisy_labels = NoisyLabelsTest(\n",
    "        base_dataset=df[features + [label]],\n",
    "        label_name=label,\n",
    "        calculate_idx_issues=True,\n",
    "        threshold = 0.2,\n",
    "        dataset_schema=schema,\n",
    "        label_issues_args={\"clf\": LogisticRegression(solver='liblinear')}\n",
    "    )\n",
    "    \n",
    "    # SampleLeaking\n",
    "    sample_leaking = SampleLeakingTest(\n",
    "        base_dataset=df_train[features + [label]], \n",
    "        test_dataset=df_test[features + [label]]\n",
    "    )\n",
    "    \n",
    "    # NoDuplicates\n",
    "    no_dups = NoDuplicatesTest(df_train)\n",
    "    \n",
    "    # Create Suite\n",
    "    test_suite = TestSuite(\n",
    "        tests=[\n",
    "            linear_combinations,\n",
    "            label_leaking,\n",
    "            noisy_labels,\n",
    "            sample_leaking,\n",
    "            no_dups\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return test_suite\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a5ca489",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>state</th>\n",
       "      <th>error</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearCombinationsTest</td>\n",
       "      <td>TestState.SUCCESS</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LabelLeakingTest</td>\n",
       "      <td>TestState.FAIL</td>\n",
       "      <td>Test failed because high importance features were detected: ['REMAINDER_SENT']. Check for possible target leaking.</td>\n",
       "      <td>{'importances': {'LIMIT_BAL': 0.5, 'SEX': 0.5, 'EDUCATION': 0.5, 'MARRIAGE': 0.5, 'PAY_AMT5': 0.5, 'PAY_AMT4': 0.5, 'PAY_AMT3': 0.5, 'BILL_AMT5': 0.5, 'PAY_AMT2': 0.5006277463904583, 'PAY_6': 0.5006277463904583, 'PAY_AMT6': 0.5006277463904583, 'PAY_4': 0.5008375288185385, 'AGE': 0.5008895742021129, 'BILL_AMT4': 0.5008895742021129, 'BILL_AMT1': 0.5009416195856874, 'BILL_AMT2': 0.5015693659761457, 'BILL_AMT3': 0.5015693659761457, 'PAY_AMT1': 0.5017791484042259, 'BILL_AMT6': 0.5021971123666039, 'PAY_3': 0.502670323500121, 'PAY_5': 0.5029321513117757, 'PAY_2': 0.5050251729112305, 'PAY_0': 0.517950821980546, 'REMAINDER_SENT': 0.9851630797824693}}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoisyLabelsTest</td>\n",
       "      <td>TestState.SUCCESS</td>\n",
       "      <td></td>\n",
       "      <td>{'rate_issues': 0.06455357142857143}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SampleLeakingTest</td>\n",
       "      <td>TestState.FAIL</td>\n",
       "      <td>Num of samples in test set that appear in train set is 402 (a proportion of 0.12 test samples )and the max allowed is 0</td>\n",
       "      <td>{'num_duplicated': 402, 'percentage_duplicated': 0.11964285714285715}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoDuplicatesTest</td>\n",
       "      <td>TestState.FAIL</td>\n",
       "      <td>Your dataset has 508 duplicates. Drop or inspect them via the `info` method</td>\n",
       "      <td>{'num_duplicated': 508, 'index_duplicates': [947, 472, 10685, 10322, 118, 11068, 10399, 10740, 432, 544, 308, 595, 69, 10304, 300, 10561, 11062, 805, 26, 10703, 51, 10893, 10839, 10299, 11035, 681, 10428, 626, 10602, 10302, 10655, 11101, 10378, 588, 34, 28, 10951, 10528, 10281, 273, 558, 507, 243, 599, 10621, 242, 325, 10734, 907, 11021, 10398, 284, 969, 240, 11019, 657, 757, 10804, 11125, 10526, 10679, 10959, 90, 983, 10753, 11162, 272, 10522, 10381, 10510, 870, 912, 11131, 886, 10751, 314, 307, 348, 71, 11196, 10923, 10997, 446, 10884, 10694, 10638, 10691, 762, 10321, 884, 10577, 10396, 10388, 650, 10537, 11177, 10597, 160, 11029, 10816, ...]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name              state  \\\n",
       "0  LinearCombinationsTest  TestState.SUCCESS   \n",
       "1        LabelLeakingTest     TestState.FAIL   \n",
       "2         NoisyLabelsTest  TestState.SUCCESS   \n",
       "3       SampleLeakingTest     TestState.FAIL   \n",
       "4        NoDuplicatesTest     TestState.FAIL   \n",
       "\n",
       "                                                                                                                     error  \\\n",
       "0                                                                                                                            \n",
       "1       Test failed because high importance features were detected: ['REMAINDER_SENT']. Check for possible target leaking.   \n",
       "2                                                                                                                            \n",
       "3  Num of samples in test set that appear in train set is 402 (a proportion of 0.12 test samples )and the max allowed is 0   \n",
       "4                                              Your dataset has 508 duplicates. Drop or inspect them via the `info` method   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            info  \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           None  \n",
       "1      {'importances': {'LIMIT_BAL': 0.5, 'SEX': 0.5, 'EDUCATION': 0.5, 'MARRIAGE': 0.5, 'PAY_AMT5': 0.5, 'PAY_AMT4': 0.5, 'PAY_AMT3': 0.5, 'BILL_AMT5': 0.5, 'PAY_AMT2': 0.5006277463904583, 'PAY_6': 0.5006277463904583, 'PAY_AMT6': 0.5006277463904583, 'PAY_4': 0.5008375288185385, 'AGE': 0.5008895742021129, 'BILL_AMT4': 0.5008895742021129, 'BILL_AMT1': 0.5009416195856874, 'BILL_AMT2': 0.5015693659761457, 'BILL_AMT3': 0.5015693659761457, 'PAY_AMT1': 0.5017791484042259, 'BILL_AMT6': 0.5021971123666039, 'PAY_3': 0.502670323500121, 'PAY_5': 0.5029321513117757, 'PAY_2': 0.5050251729112305, 'PAY_0': 0.517950821980546, 'REMAINDER_SENT': 0.9851630797824693}}  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           {'rate_issues': 0.06455357142857143}  \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          {'num_duplicated': 402, 'percentage_duplicated': 0.11964285714285715}  \n",
       "4  {'num_duplicated': 508, 'index_duplicates': [947, 472, 10685, 10322, 118, 11068, 10399, 10740, 432, 544, 308, 595, 69, 10304, 300, 10561, 11062, 805, 26, 10703, 51, 10893, 10839, 10299, 11035, 681, 10428, 626, 10602, 10302, 10655, 11101, 10378, 588, 34, 28, 10951, 10528, 10281, 273, 558, 507, 243, 599, 10621, 242, 325, 10734, 907, 11021, 10398, 284, 969, 240, 11019, 657, 757, 10804, 11125, 10526, 10679, 10959, 90, 983, 10753, 11162, 272, 10522, 10381, 10510, 870, 912, 11131, 886, 10751, 314, 307, 348, 71, 11196, 10923, 10997, 446, 10884, 10694, 10638, 10691, 762, 10321, 884, 10577, 10396, 10388, 650, 10537, 11177, 10597, 160, 11029, 10816, ...]}  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_suite = create_suite(df, df_train, df_test, schema, features, label)\n",
    "test_results = test_suite.run()\n",
    "test_suite.get_results_as_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5267e1ac",
   "metadata": {},
   "source": [
    "## Save Dataset and Data Schema\n",
    "\n",
    "Let's save our generated dataset and the `DataSchema`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a27e2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = \"./dataset/\"\n",
    "\n",
    "if not os.path.exists(path_dataset):\n",
    "    os.makedirs(path_dataset)\n",
    "\n",
    "df.to_csv(path_dataset + \"all.csv\", index=False)\n",
    "df_train.to_csv(path_dataset + \"train.csv\", index=False)\n",
    "df_test.to_csv(path_dataset + \"test.csv\", index=False)\n",
    "\n",
    "schema.save(path_dataset + \"schema.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724efe8a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "<a id=\"[1]\">[1]</a>\n",
    "Yeh, I. C., & Lien, C. H. (2009). The comparisons of data mining techniques for the predictive accuracy of probability of default of credit card clients. Expert Systems with Applications, 36(2), 2473-2480. https://archive.ics.uci.edu/ml/datasets/default+of+credit+card+clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b2d202",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
